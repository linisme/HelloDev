#!/usr/bin/env python3
"""
HelloDev å‘å¸ƒæ‘˜è¦ç”Ÿæˆè„šæœ¬

ä¸ºå‘å¸ƒçš„æ—¥æŠ¥ç”Ÿæˆç®€æ´çš„æ‘˜è¦ä¿¡æ¯ï¼Œç”¨äºç¤¾äº¤åª’ä½“åˆ†å‘ã€‚
"""

import os
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional


def read_article_content(article_path: str) -> Optional[str]:
    """è¯»å–æ–‡ç« å†…å®¹"""
    try:
        with open(article_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"è¯»å–æ–‡ç« å¤±è´¥: {article_path}, é”™è¯¯: {e}")
        return None


def extract_article_summary(content: str) -> Dict:
    """æå–æ–‡ç« å…³é”®ä¿¡æ¯"""
    lines = content.split('\n')
    
    # æå–æ ‡é¢˜
    title = None
    for line in lines:
        if line.startswith('# '):
            title = line[2:].strip()
            break
    
    # æå–ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯»æ‰¾ğŸ“Š ä»Šæ—¥ç»Ÿè®¡éƒ¨åˆ†ï¼‰
    stats = {}
    in_stats = False
    for line in lines:
        if 'ğŸ“Š' in line and 'ä»Šæ—¥ç»Ÿè®¡' in line:
            in_stats = True
            continue
        elif in_stats and line.startswith('---'):
            break
        elif in_stats and line.strip().startswith('-'):
            # è§£æç»Ÿè®¡è¡Œï¼Œå¦‚ "- ğŸš€ æŠ€æœ¯åˆ†äº«ï¼šXæ¡"
            match = re.search(r'- ([^ï¼š]+)ï¼š(\d+)æ¡', line)
            if match:
                category = match.group(1).strip()
                count = int(match.group(2))
                stats[category] = count
    
    # æå–åˆ†ç±»å†…å®¹ï¼ˆç»Ÿè®¡å„åˆ†ç±»çš„é¡¹ç›®ï¼‰
    categories = {}
    current_category = None
    current_items = []
    
    for line in lines:
        # æ£€æµ‹åˆ†ç±»æ ‡é¢˜
        if line.startswith('## ') and any(emoji in line for emoji in ['ğŸš€', 'ğŸ› ï¸', 'ğŸ“°', 'ğŸ’¡', 'ğŸ“¸']):
            if current_category and current_items:
                categories[current_category] = current_items
            current_category = line[3:].strip()
            current_items = []
        
        # æ£€æµ‹é¡¹ç›®æ ‡é¢˜
        elif line.startswith('### ') and current_category:
            # æå–é¡¹ç›®åç§°ï¼ˆå»æ‰é“¾æ¥æ ¼å¼ï¼‰
            project_title = line[4:].strip()
            # å»æ‰markdowné“¾æ¥æ ¼å¼ [title](url)
            project_title = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', project_title)
            current_items.append(project_title)
    
    # æ·»åŠ æœ€åä¸€ä¸ªåˆ†ç±»
    if current_category and current_items:
        categories[current_category] = current_items
    
    # ç»Ÿè®¡æ€»æ•°
    total_items = sum(len(items) for items in categories.values())
    
    return {
        'title': title or 'æœªçŸ¥æ ‡é¢˜',
        'stats': stats,
        'categories': categories,
        'total_items': total_items,
        'category_count': len(categories)
    }


def generate_social_summary(summary: Dict, article_date: str) -> Dict:
    """ç”Ÿæˆç¤¾äº¤åª’ä½“æ‘˜è¦"""
    
    # å¾®ä¿¡å…¬ä¼—å·æ‘˜è¦ï¼ˆè¾ƒè¯¦ç»†ï¼‰
    wechat_summary = f"""ğŸ”¥ HelloDev å¼€å‘è€…æ—¥æŠ¥ - {article_date}

ä»Šæ—¥ä¸ºå¤§å®¶ç²¾é€‰äº† {summary['total_items']} æ¡ä¼˜è´¨æŠ€æœ¯å†…å®¹ï¼š

"""
    
    for category, items in summary['categories'].items():
        if items:
            wechat_summary += f"{category} {len(items)}æ¡\n"
    
    wechat_summary += f"""
æ¶µç›–äº†å¼€æºé¡¹ç›®ã€å¼€å‘å·¥å…·ã€æŠ€æœ¯åŠ¨æ€ç­‰å¤šä¸ªæ–¹é¢ã€‚æ¯ä¸€æ¡éƒ½ç»è¿‡ç²¾å¿ƒç­›é€‰ï¼Œç¡®ä¿å¯¹å¼€å‘è€…æœ‰å®é™…ä»·å€¼ã€‚

ğŸ‘‰ ç‚¹å‡»é˜…è¯»å®Œæ•´å†…å®¹ï¼Œå‘ç°ä»Šæ—¥æŠ€æœ¯äº®ç‚¹ï¼

#å¼€å‘è€…æ—¥æŠ¥ #æŠ€æœ¯èµ„è®¯ #HelloDev"""

    # æ˜é‡‘æ‘˜è¦ï¼ˆä¸­ç­‰é•¿åº¦ï¼‰
    juejin_summary = f"""HelloDev æ—¥æŠ¥ {article_date} | ä»Šæ—¥ {summary['total_items']} æ¡ç²¾é€‰

"""
    
    top_categories = sorted(summary['categories'].items(), key=lambda x: len(x[1]), reverse=True)[:3]
    for category, items in top_categories:
        if items:
            juejin_summary += f"â€¢ {category}: {items[0]}\n"
    
    juejin_summary += "\næ›´å¤šç²¾å½©å†…å®¹ï¼Œç‚¹å‡»æŸ¥çœ‹å®Œæ•´æ—¥æŠ¥ ğŸ‘†"

    # çŸ¥ä¹æ‘˜è¦ï¼ˆç®€æ´ç‰ˆï¼‰
    zhihu_summary = f"""HelloDev å¼€å‘è€…æ—¥æŠ¥ {article_date}

ä»Šæ—¥ç²¾é€‰ {summary['total_items']} æ¡æŠ€æœ¯èµ„è®¯ï¼ŒåŒ…å«å¼€æºé¡¹ç›®ã€å¼€å‘å·¥å…·ã€è¡Œä¸šåŠ¨æ€ç­‰ã€‚

é‡ç‚¹æ¨èï¼š"""
    
    if summary['categories']:
        first_category = list(summary['categories'].values())[0]
        if first_category:
            zhihu_summary += f"\nâ€¢ {first_category[0]}"
    
    zhihu_summary += "\n\nè¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹å®Œæ•´æ—¥æŠ¥ã€‚"

    return {
        'wechat': wechat_summary,
        'juejin': juejin_summary,
        'zhihu': zhihu_summary,
        'short': f"HelloDev æ—¥æŠ¥ {article_date} - {summary['total_items']} æ¡ç²¾é€‰æŠ€æœ¯èµ„è®¯"
    }


def save_summary_files(article_info: Dict, summary: Dict, social_summaries: Dict):
    """ä¿å­˜æ‘˜è¦æ–‡ä»¶"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path('config/summaries')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å®Œæ•´æ‘˜è¦æ•°æ®
    full_summary = {
        'article_info': article_info,
        'content_summary': summary,
        'social_summaries': social_summaries,
        'generated_at': datetime.now().isoformat()
    }
    
    # ä¿å­˜å®Œæ•´æ‘˜è¦
    date_str = article_info.get('date', datetime.now().strftime('%Y-%m-%d'))
    summary_file = output_dir / f"summary_{date_str.replace('-', '')}.json"
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(full_summary, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æœ€æ–°æ‘˜è¦ï¼ˆä¾›è„šæœ¬ä½¿ç”¨ï¼‰
    with open('config/latest_summary.json', 'w', encoding='utf-8') as f:
        json.dump(full_summary, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ æ‘˜è¦å·²ä¿å­˜: {summary_file}")


def create_article_info_from_path(article_path: str) -> Optional[Dict]:
    """ä»æ–‡ç« è·¯å¾„åˆ›å»ºæ–‡ç« ä¿¡æ¯"""
    if not os.path.exists(article_path):
        print(f"âŒ æ–‡ç« æ–‡ä»¶ä¸å­˜åœ¨: {article_path}")
        return None
    
    try:
        with open(article_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ ‡é¢˜
        title = None
        for line in content.split('\n'):
            if line.startswith('# '):
                title = line[2:].strip()
                break
        
        # ä»è·¯å¾„æå–æ—¥æœŸ
        path_parts = article_path.split('/')
        if len(path_parts) >= 3:
            date_part = path_parts[2]  # æ ¼å¼å¦‚ 07-31
            year = path_parts[1]       # æ ¼å¼å¦‚ 2025
            date_str = f"{year}-{date_part}"
        else:
            date_str = datetime.now().strftime("%Y-%m-%d")
        
        # æ£€æŸ¥å›¾ç‰‡å’Œç¼©ç•¥å›¾
        article_dir = os.path.dirname(article_path)
        has_images = os.path.exists(os.path.join(article_dir, 'images'))
        has_thumb = os.path.exists(os.path.join(article_dir, 'thumb.jpg'))
        
        return {
            'path': article_path,
            'title': title or 'æœªçŸ¥æ ‡é¢˜',
            'date': date_str,
            'has_images': has_images,
            'has_thumb': has_thumb,
            'content_length': len(content),
            'detected_at': datetime.now().isoformat()
        }
    
    except Exception as e:
        print(f"âŒ è§£ææ–‡ç« ä¿¡æ¯å¤±è´¥: {article_path}, é”™è¯¯: {e}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    print("ğŸ“ HelloDev å‘å¸ƒæ‘˜è¦ç”Ÿæˆå¼€å§‹...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # ç›´æ¥å¤„ç†å‘½ä»¤è¡ŒæŒ‡å®šçš„æ–‡ç« 
        article_paths = sys.argv[1].strip().split()
        articles_info = []
        
        for article_path in article_paths:
            article_path = article_path.strip()
            if article_path:
                info = create_article_info_from_path(article_path)
                if info:
                    articles_info.append(info)
        
        if not articles_info:
            print("âŒ æœªèƒ½è§£æä»»ä½•æœ‰æ•ˆçš„æ–‡ç« ")
            return
            
    else:
        # ä»é…ç½®æ–‡ä»¶è¯»å–å˜æ›´ä¿¡æ¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        changes_file = 'config/latest_changes.json'
        if not os.path.exists(changes_file):
            print("âŒ æœªæ‰¾åˆ°å˜æ›´ä¿¡æ¯æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ detect_changes.py æˆ–æä¾›æ–‡ç« è·¯å¾„å‚æ•°")
            return
        
        with open(changes_file, 'r', encoding='utf-8') as f:
            changes_data = json.load(f)
        
        if not changes_data.get('articles'):
            print("ğŸ“° æœªå‘ç°éœ€è¦å¤„ç†çš„æ–‡ç« ")
            return
            
        articles_info = changes_data['articles']
    
    # å¤„ç†æ¯ç¯‡æ–‡ç« 
    for article_info in articles_info:
        article_path = article_info['path']
        print(f"ğŸ“„ å¤„ç†æ–‡ç« : {article_info['title']}")
        
        # è¯»å–æ–‡ç« å†…å®¹
        content = read_article_content(article_path)
        if not content:
            continue
        
        # æå–æ‘˜è¦
        summary = extract_article_summary(content)
        print(f"  ğŸ“Š å‘ç° {summary['total_items']} æ¡å†…å®¹ï¼Œ{summary['category_count']} ä¸ªåˆ†ç±»")
        
        # ç”Ÿæˆç¤¾äº¤åª’ä½“æ‘˜è¦
        social_summaries = generate_social_summary(summary, article_info['date'])
        
        # ä¿å­˜æ‘˜è¦æ–‡ä»¶
        save_summary_files(article_info, summary, social_summaries)
        
        print(f"  âœ… {article_info['title']} æ‘˜è¦ç”Ÿæˆå®Œæˆ")
    
    print("ğŸ‰ æ‘˜è¦ç”Ÿæˆå®Œæˆ!")


if __name__ == '__main__':
    main()